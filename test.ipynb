{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "import logging\n",
    "import pathlib, os\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded here: /home/toghrul/ada/ml/final/datasets/scifact\n"
     ]
    }
   ],
   "source": [
    "import pathlib, os\n",
    "from beir import util\n",
    "\n",
    "dataset = \"scifact\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "print(\"Dataset downloaded here: {}\".format(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus.jsonl  embeddings.csv  qrels  queries.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls datasets/scifact/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 15:52:37 - Loading Corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88649774a25470f95c28dabb17a0a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 15:52:37 - Loaded 5183 TEST Documents.\n",
      "2024-05-22 15:52:37 - Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}\n",
      "2024-05-22 15:52:37 - Loading Queries...\n",
      "2024-05-22 15:52:37 - Loaded 300 TEST Queries.\n",
      "2024-05-22 15:52:37 - Query Example: 0-dimensional biomaterials show inductive properties.\n"
     ]
    }
   ],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_idx = list(corpus.keys())\n",
    "corpus_vals = list(corpus.values())\n",
    "\n",
    "corpus_df = pd.DataFrame(corpus_vals, index=corpus_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>Alterations of the architecture of cerebral wh...</td>\n",
       "      <td>Microstructural development of human newborn c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>Myelodysplastic syndromes (MDS) are age-depend...</td>\n",
       "      <td>Induction of myelodysplasia by myeloid-derived...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>ID elements are short interspersed elements (S...</td>\n",
       "      <td>BC1 RNA, the transcript from a master gene for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18670</th>\n",
       "      <td>DNA methylation plays an important role in bio...</td>\n",
       "      <td>The DNA Methylome of Human Peripheral Blood Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19238</th>\n",
       "      <td>Two human Golli (for gene expressed in the oli...</td>\n",
       "      <td>The human myelin basic protein gene is include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195689316</th>\n",
       "      <td>BACKGROUND The main associations of body-mass ...</td>\n",
       "      <td>Body-mass index and cause-specific mortality i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195689757</th>\n",
       "      <td>A key aberrant biological difference between t...</td>\n",
       "      <td>Targeting metabolic remodeling in glioblastoma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196664003</th>\n",
       "      <td>A signaling pathway transmits information from...</td>\n",
       "      <td>Signaling architectures that transmit unidirec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198133135</th>\n",
       "      <td>AIMS Trabecular bone score (TBS) is a surrogat...</td>\n",
       "      <td>Association between pre-diabetes, type 2 diabe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198309074</th>\n",
       "      <td>Introduction: Among the inflammatory mediators...</td>\n",
       "      <td>Adhesion molecules and chemokines: relation to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  \\\n",
       "4983       Alterations of the architecture of cerebral wh...   \n",
       "5836       Myelodysplastic syndromes (MDS) are age-depend...   \n",
       "7912       ID elements are short interspersed elements (S...   \n",
       "18670      DNA methylation plays an important role in bio...   \n",
       "19238      Two human Golli (for gene expressed in the oli...   \n",
       "...                                                      ...   \n",
       "195689316  BACKGROUND The main associations of body-mass ...   \n",
       "195689757  A key aberrant biological difference between t...   \n",
       "196664003  A signaling pathway transmits information from...   \n",
       "198133135  AIMS Trabecular bone score (TBS) is a surrogat...   \n",
       "198309074  Introduction: Among the inflammatory mediators...   \n",
       "\n",
       "                                                       title  \n",
       "4983       Microstructural development of human newborn c...  \n",
       "5836       Induction of myelodysplasia by myeloid-derived...  \n",
       "7912       BC1 RNA, the transcript from a master gene for...  \n",
       "18670      The DNA Methylome of Human Peripheral Blood Mo...  \n",
       "19238      The human myelin basic protein gene is include...  \n",
       "...                                                      ...  \n",
       "195689316  Body-mass index and cause-specific mortality i...  \n",
       "195689757  Targeting metabolic remodeling in glioblastoma...  \n",
       "196664003  Signaling architectures that transmit unidirec...  \n",
       "198133135  Association between pre-diabetes, type 2 diabe...  \n",
       "198309074  Adhesion molecules and chemokines: relation to...  \n",
       "\n",
       "[5183 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df = pd.Series(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import logging\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# from rag import insert_document_and_embeddings, find_similar_embeddings, preprocess\n",
    "from datetime import datetime\n",
    "import re\n",
    "from nltk import tokenize\n",
    "import unicodedata\n",
    "import string\n",
    "import logging\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "MAX_WORD_COUNT = 256\n",
    "MAX_TOKEN_COUNT = 512\n",
    "\n",
    "\n",
    "model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def encoding(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove unicoded data\n",
    "    \"\"\"\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_URL(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove URLs\n",
    "    \"\"\"\n",
    "    return re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "\n",
    "\n",
    "def remove_non_ascii(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove non-ASCII characters\n",
    "    \"\"\"\n",
    "    return re.sub(r\"[^\\x00-\\x7f]\", r\"\", text)\n",
    "\n",
    "\n",
    "def remove_html(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove the html\n",
    "    \"\"\"\n",
    "    html = re.compile(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\")\n",
    "    return re.sub(html, \"\", text)\n",
    "\n",
    "\n",
    "def remove_punct(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove the punctuation\n",
    "    \"\"\"\n",
    "    #     return re.sub(r'[]!\"$%&\\'()*+,./:;=#@?[\\\\^_`{|}~-]+', \"\", text)\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess the text\n",
    "    \"\"\"\n",
    "\n",
    "    text = encoding(text)\n",
    "    text = remove_URL(text)\n",
    "    text = remove_non_ascii(text)\n",
    "    text = remove_html(text)\n",
    "    # text = remove_punct(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def ingest_input(user_input):\n",
    "    user_input = preprocess(user_input)\n",
    "    logging.info(f\"Preprocessed user input\")\n",
    "\n",
    "    # Generate sentence tokens\n",
    "    sentence_tokens = tokenize.sent_tokenize(user_input)\n",
    "    model_input = []\n",
    "    temp_input: str = \"\"\n",
    "    if len(user_input.split(\" \")) > MAX_WORD_COUNT:\n",
    "        logging.info(\n",
    "            f\"Input contains more than {MAX_WORD_COUNT} words. Splitting the input into chunks\"\n",
    "        )\n",
    "\n",
    "        # Split the input into chunks based on the sentence tokens\n",
    "        for i, sent in enumerate(sentence_tokens):\n",
    "            num_words_sent = len(sent.split(\" \"))\n",
    "\n",
    "            # Check if the new chunk would exceed the maximum word count\n",
    "            if len(temp_input.split(\" \")) + num_words_sent > MAX_WORD_COUNT:\n",
    "\n",
    "                # Append the chunk to the model input\n",
    "                model_input.append(temp_input.strip())\n",
    "                logging.info(\n",
    "                    f\"Number of words in the chunk: {len(temp_input.split(' '))}\"\n",
    "                )\n",
    "                temp_input = sent\n",
    "            else:\n",
    "                temp_input += \" \" + sent\n",
    "\n",
    "        # Append the last chunk to the model input\n",
    "        model_input.append(temp_input)\n",
    "    else:\n",
    "        model_input = [user_input]\n",
    "\n",
    "    return model_input\n",
    "\n",
    "\n",
    "def read_pdf_doc(filepath):\n",
    "    doc = fitz.open(filepath)\n",
    "    text = \"\"\n",
    "    for page_index, page in enumerate(doc):\n",
    "        logging.info(f\"page {page_index+1} out of {len(doc)}\")\n",
    "        tp = page.get_textpage()\n",
    "        words = tp.extractWORDS()\n",
    "\n",
    "        page_text = \" \".join([word[4] for word in words])\n",
    "        text += page_text + \" \"\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "def generate_embeddings(text, device):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_TOKEN_COUNT,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    outputs = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    # Scale the embeddings to be between 0 and 1\n",
    "    outputs = (outputs - outputs.min()) / (outputs.max() - outputs.min())\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alterations of the architecture of cerebral wh...</td>\n",
       "      <td>[0.4130120873451233, 0.48207804560661316, 0.38...</td>\n",
       "      <td>4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The data indicate that quantitative assessment...</td>\n",
       "      <td>[0.3933950662612915, 0.5030855536460876, 0.306...</td>\n",
       "      <td>4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Myelodysplastic syndromes (MDS) are age-depend...</td>\n",
       "      <td>[0.35396137833595276, 0.3293021619319916, 0.39...</td>\n",
       "      <td>5836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID elements are short interspersed elements (S...</td>\n",
       "      <td>[0.46460971236228943, 0.2978157699108124, 0.44...</td>\n",
       "      <td>7912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DNA methylation plays an important role in bio...</td>\n",
       "      <td>[0.3715234696865082, 0.3990043103694916, 0.436...</td>\n",
       "      <td>18670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Alterations of the architecture of cerebral wh...   \n",
       "1  The data indicate that quantitative assessment...   \n",
       "2  Myelodysplastic syndromes (MDS) are age-depend...   \n",
       "3  ID elements are short interspersed elements (S...   \n",
       "4  DNA methylation plays an important role in bio...   \n",
       "\n",
       "                                           embedding  doc_id  \n",
       "0  [0.4130120873451233, 0.48207804560661316, 0.38...    4983  \n",
       "1  [0.3933950662612915, 0.5030855536460876, 0.306...    4983  \n",
       "2  [0.35396137833595276, 0.3293021619319916, 0.39...    5836  \n",
       "3  [0.46460971236228943, 0.2978157699108124, 0.44...    7912  \n",
       "4  [0.3715234696865082, 0.3990043103694916, 0.436...   18670  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2226/2909947374.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mids_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing documents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtext_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mingest_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "text_chunks_list = []\n",
    "embeddings_list = []\n",
    "doc_ids = []\n",
    "\n",
    "batch_size = 128\n",
    "batch_no = 0\n",
    "text_batch = []\n",
    "ids_batch = []\n",
    "\n",
    "for idx, doc in tqdm(corpus_df.iterrows(), total=len(corpus_df), desc=\"Processing documents\"):\n",
    "    text_chunks = ingest_input(doc['text'])\n",
    "\n",
    "    start = time.time()\n",
    "    text_batch.extend(text_chunks)\n",
    "    ids_batch.extend([idx] * len(text_chunks))\n",
    "\n",
    "    if len(text_batch) == batch_size:\n",
    "        embeddings = generate_embeddings(text_batch, device)\n",
    "        embeddings_list.append(embeddings)\n",
    "        text_chunks_list.extend(text_batch)\n",
    "        doc_ids.extend(ids_batch)\n",
    "\n",
    "        logging.info(f\">>> Generated embeddings for batch {batch_no}\")\n",
    "        logging.info(f\"Shape of embeddings: {embeddings.shape}\")\n",
    "        logging.info(f\"Time taken for the batch: {time.time() - start}\")\n",
    "\n",
    "        text_batch = []\n",
    "        ids_batch = []\n",
    "        batch_no += 1\n",
    "        \n",
    "# Handle any remaining batches\n",
    "if len(text_batch) > 0:\n",
    "    embeddings = generate_embeddings(text_batch, device)\n",
    "    embeddings_list.append(embeddings)\n",
    "    text_chunks_list.extend(text_batch)\n",
    "    doc_ids.extend(ids_batch)\n",
    "\n",
    "    logging.info(f\">>> Generated embeddings for final batch {batch_no}\")\n",
    "    logging.info(f\"Shape of embeddings: {embeddings.shape}\")\n",
    "    logging.info(f\"Time taken for the batch: {time.time() - start}\")\n",
    "\n",
    "embeddings_list = np.concatenate(embeddings_list, axis=0)\n",
    "doc_ids = np.array(doc_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the embeddings and doc_ids to a DataFrame\n",
    "embeddings_df = pd.DataFrame({\n",
    "    'text': text_chunks_list,\n",
    "    'embedding': embeddings_list.tolist(),\n",
    "    'doc_id': doc_ids\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.to_csv(os.path.join(data_path, \"embeddings.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.read_csv(os.path.join(data_path, \"embeddings.csv\"))\n",
    "# embeddings_df.loc[:, \"embedding\"] = embeddings_df[\"embedding\"].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df[\"embedding\"] = embeddings_df[\"embedding\"].apply(lambda x: x[1:-1].split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         object\n",
       "embedding    object\n",
       "doc_id        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'31715818': 1},\n",
       " '3': {'14717500': 1},\n",
       " '5': {'13734012': 1},\n",
       " '13': {'1606628': 1},\n",
       " '36': {'5152028': 1, '11705328': 1},\n",
       " '42': {'18174210': 1},\n",
       " '48': {'13734012': 1},\n",
       " '49': {'5953485': 1},\n",
       " '50': {'12580014': 1},\n",
       " '51': {'45638119': 1},\n",
       " '53': {'45638119': 1},\n",
       " '54': {'49556906': 1},\n",
       " '56': {'4709641': 1},\n",
       " '57': {'4709641': 1},\n",
       " '70': {'5956380': 1, '4414547': 1},\n",
       " '72': {'6076903': 1},\n",
       " '75': {'4387784': 1},\n",
       " '94': {'1215116': 1},\n",
       " '99': {'18810195': 1},\n",
       " '100': {'4381486': 1},\n",
       " '113': {'6157837': 1},\n",
       " '115': {'33872649': 1},\n",
       " '118': {'6372244': 1},\n",
       " '124': {'4883040': 1},\n",
       " '127': {'21598000': 1},\n",
       " '128': {'8290953': 1},\n",
       " '129': {'27768226': 1},\n",
       " '130': {'27768226': 1},\n",
       " '132': {'7975937': 1},\n",
       " '133': {'38485364': 1,\n",
       "  '6969753': 1,\n",
       "  '17934082': 1,\n",
       "  '16280642': 1,\n",
       "  '12640810': 1},\n",
       " '137': {'26016929': 1},\n",
       " '141': {'6955746': 1, '14437255': 1},\n",
       " '142': {'10582939': 1},\n",
       " '143': {'10582939': 1},\n",
       " '146': {'10582939': 1},\n",
       " '148': {'1084345': 1},\n",
       " '163': {'18872233': 1},\n",
       " '171': {'12670680': 1},\n",
       " '179': {'16322674': 1, '27123743': 1, '23557241': 1, '17450673': 1},\n",
       " '180': {'16966326': 1},\n",
       " '183': {'12827098': 1},\n",
       " '185': {'18340282': 1},\n",
       " '198': {'2177022': 1},\n",
       " '208': {'13519661': 1},\n",
       " '212': {'22038539': 1},\n",
       " '213': {'13625993': 1},\n",
       " '216': {'21366394': 1},\n",
       " '217': {'21366394': 1},\n",
       " '218': {'21366394': 1},\n",
       " '219': {'21366394': 1},\n",
       " '230': {'3067015': 1},\n",
       " '232': {'10536636': 1},\n",
       " '233': {'4388470': 1},\n",
       " '236': {'4388470': 1},\n",
       " '237': {'4942718': 1},\n",
       " '238': {'2251426': 1},\n",
       " '239': {'14079881': 1},\n",
       " '248': {'1568684': 1},\n",
       " '249': {'1568684': 1},\n",
       " '261': {'1122279': 1, '10697096': 1},\n",
       " '268': {'970012': 1},\n",
       " '269': {'970012': 1},\n",
       " '274': {'11614737': 1},\n",
       " '275': {'4961038': 1, '14241418': 1, '14819804': 1},\n",
       " '279': {'14376683': 1},\n",
       " '294': {'10874408': 1},\n",
       " '295': {'20310709': 1},\n",
       " '298': {'39381118': 1},\n",
       " '300': {'3553087': 1},\n",
       " '303': {'4388470': 1},\n",
       " '312': {'6173523': 1},\n",
       " '314': {'4347374': 1},\n",
       " '324': {'2014909': 1},\n",
       " '327': {'17997584': 1},\n",
       " '338': {'23349986': 1},\n",
       " '343': {'7873737': 1, '5884524': 1},\n",
       " '350': {'16927286': 1},\n",
       " '354': {'8774475': 1},\n",
       " '362': {'38587347': 1},\n",
       " '380': {'19005293': 1},\n",
       " '384': {'13770184': 1},\n",
       " '385': {'9955779': 1, '9767444': 1},\n",
       " '386': {'16495649': 1},\n",
       " '388': {'1148122': 1},\n",
       " '399': {'791050': 1},\n",
       " '410': {'14924526': 1},\n",
       " '411': {'14924526': 1},\n",
       " '415': {'6309659': 1},\n",
       " '421': {'11172205': 1},\n",
       " '431': {'28937856': 1},\n",
       " '436': {'14637235': 1},\n",
       " '437': {'18399038': 1},\n",
       " '439': {'4423559': 1},\n",
       " '440': {'4423559': 1},\n",
       " '443': {'10165258': 1},\n",
       " '452': {'12804937': 1, '464511': 1},\n",
       " '475': {'18678095': 1},\n",
       " '478': {'14767844': 1},\n",
       " '491': {'56893404': 1},\n",
       " '501': {'17930286': 1},\n",
       " '502': {'13071728': 1},\n",
       " '507': {'30774694': 1},\n",
       " '508': {'13980338': 1},\n",
       " '513': {'13230773': 1},\n",
       " '514': {'16256507': 1},\n",
       " '516': {'29564505': 1},\n",
       " '517': {'15663829': 1},\n",
       " '521': {'34873974': 1},\n",
       " '525': {'13639330': 1},\n",
       " '527': {'3863543': 1},\n",
       " '528': {'5476778': 1},\n",
       " '532': {'12991445': 1},\n",
       " '533': {'12991445': 1},\n",
       " '535': {'39368721': 1},\n",
       " '536': {'16056514': 1},\n",
       " '539': {'13282296': 1},\n",
       " '540': {'11886686': 1, '25007443': 1},\n",
       " '544': {'24221369': 1},\n",
       " '549': {'9433958': 1},\n",
       " '551': {'33499189': 1},\n",
       " '552': {'1471041': 1},\n",
       " '554': {'1049501': 1},\n",
       " '560': {'40096222': 1},\n",
       " '569': {'23460562': 1},\n",
       " '575': {'10300888': 1},\n",
       " '577': {'5289038': 1},\n",
       " '578': {'8764879': 1},\n",
       " '587': {'16999023': 1},\n",
       " '589': {'10984005': 1},\n",
       " '593': {'19675911': 1},\n",
       " '597': {'12779444': 1, '36355784': 1, '25742130': 1},\n",
       " '598': {'25742130': 1},\n",
       " '613': {'9638032': 1},\n",
       " '619': {'20888849': 1, '2565138': 1},\n",
       " '623': {'17000834': 1},\n",
       " '628': {'24512064': 1},\n",
       " '636': {'24294572': 1},\n",
       " '637': {'25649714': 1},\n",
       " '641': {'5912283': 1, '31554917': 1},\n",
       " '644': {'13619127': 1},\n",
       " '649': {'12789595': 1},\n",
       " '659': {'1215116': 1},\n",
       " '660': {'1215116': 1},\n",
       " '674': {'2095573': 1},\n",
       " '684': {'4942718': 1},\n",
       " '690': {'18750453': 1},\n",
       " '691': {'10991183': 1},\n",
       " '692': {'24088502': 1},\n",
       " '693': {'24088502': 1},\n",
       " '700': {'4350400': 1},\n",
       " '702': {'4350400': 1},\n",
       " '715': {'18421962': 1},\n",
       " '716': {'18421962': 1},\n",
       " '718': {'17587795': 1},\n",
       " '721': {'1834762': 1},\n",
       " '723': {'5531479': 1},\n",
       " '727': {'7521113': 1},\n",
       " '728': {'7521113': 1, '36444198': 1},\n",
       " '729': {'26851674': 1},\n",
       " '742': {'32159283': 1},\n",
       " '743': {'32159283': 1},\n",
       " '744': {'8460275': 1},\n",
       " '756': {'2831620': 1},\n",
       " '759': {'1805641': 1},\n",
       " '768': {'6421792': 1},\n",
       " '770': {'15476777': 1},\n",
       " '775': {'32275758': 1},\n",
       " '781': {'24338780': 1},\n",
       " '783': {'40632104': 1},\n",
       " '784': {'2356950': 1},\n",
       " '785': {'12471115': 1},\n",
       " '793': {'8551160': 1},\n",
       " '800': {'22543403': 1},\n",
       " '805': {'22180793': 1},\n",
       " '808': {'36606083': 1},\n",
       " '811': {'19799455': 1},\n",
       " '814': {'33387953': 1},\n",
       " '820': {'8646760': 1},\n",
       " '821': {'8646760': 1},\n",
       " '823': {'15319019': 1},\n",
       " '830': {'1897324': 1},\n",
       " '831': {'1897324': 1},\n",
       " '832': {'30303335': 1},\n",
       " '834': {'5483793': 1},\n",
       " '837': {'15928989': 1},\n",
       " '839': {'1469751': 1},\n",
       " '845': {'17741440': 1},\n",
       " '847': {'16787954': 1},\n",
       " '852': {'13843341': 1},\n",
       " '859': {'1982286': 1},\n",
       " '870': {'195689316': 1},\n",
       " '873': {'1180972': 1,\n",
       "  '19307912': 1,\n",
       "  '27393799': 1,\n",
       "  '29025270': 1,\n",
       "  '3315558': 1},\n",
       " '879': {'8426046': 1},\n",
       " '880': {'8426046': 1},\n",
       " '882': {'14803797': 1},\n",
       " '887': {'18855191': 1},\n",
       " '903': {'10648422': 1},\n",
       " '904': {'7370282': 1},\n",
       " '907': {'6923961': 1},\n",
       " '911': {'11254556': 1},\n",
       " '913': {'3203590': 1},\n",
       " '914': {'3203590': 1},\n",
       " '921': {'1642727': 1},\n",
       " '922': {'17077004': 1},\n",
       " '936': {'5483793': 1},\n",
       " '956': {'12956194': 1},\n",
       " '957': {'123859': 1},\n",
       " '960': {'8780599': 1},\n",
       " '967': {'2119889': 1, '8997410': 1},\n",
       " '971': {'46695481': 1, '27873158': 1, '28617573': 1, '9764256': 1},\n",
       " '975': {'5304891': 1},\n",
       " '982': {'2988714': 1},\n",
       " '985': {'6828370': 1},\n",
       " '993': {'16472469': 1},\n",
       " '1012': {'9745001': 1},\n",
       " '1014': {'6277638': 1},\n",
       " '1019': {'11603066': 1},\n",
       " '1020': {'9433958': 1},\n",
       " '1021': {'9433958': 1},\n",
       " '1024': {'5373138': 1},\n",
       " '1029': {'13923140': 1, '13940200': 1, '11899391': 1},\n",
       " '1041': {'25254425': 1, '16626264': 1},\n",
       " '1049': {'12486491': 1},\n",
       " '1062': {'20381484': 1},\n",
       " '1086': {'39281140': 1},\n",
       " '1088': {'37549932': 1},\n",
       " '1089': {'17628888': 1},\n",
       " '1099': {'7662206': 1},\n",
       " '1100': {'7662206': 1},\n",
       " '1104': {'3898784': 1},\n",
       " '1107': {'20532591': 1},\n",
       " '1110': {'13770184': 1},\n",
       " '1121': {'4456756': 1},\n",
       " '1130': {'17997584': 1},\n",
       " '1132': {'33499189': 1, '9283422': 1},\n",
       " '1137': {'33370': 1},\n",
       " '1140': {'12009265': 1},\n",
       " '1144': {'10071552': 1},\n",
       " '1146': {'13906581': 1},\n",
       " '1150': {'11369420': 1},\n",
       " '1163': {'15305881': 1},\n",
       " '1175': {'31272411': 1},\n",
       " '1179': {'31272411': 1},\n",
       " '1180': {'31272411': 1},\n",
       " '1185': {'16737210': 1},\n",
       " '1187': {'52873726': 1},\n",
       " '1191': {'30655442': 1},\n",
       " '1194': {'11419230': 1},\n",
       " '1196': {'25649714': 1},\n",
       " '1197': {'25649714': 1},\n",
       " '1199': {'16760369': 1},\n",
       " '1200': {'3441524': 1},\n",
       " '1202': {'3475317': 1},\n",
       " '1204': {'31141365': 1},\n",
       " '1207': {'18909530': 1},\n",
       " '1213': {'14407673': 1},\n",
       " '1216': {'24142891': 1},\n",
       " '1221': {'19736671': 1},\n",
       " '1225': {'9650982': 1},\n",
       " '1226': {'13777138': 1},\n",
       " '1232': {'13905670': 1},\n",
       " '1241': {'4427392': 1},\n",
       " '1245': {'7662395': 1},\n",
       " '1259': {'24341590': 1},\n",
       " '1262': {'44172171': 1},\n",
       " '1266': {'37480103': 1},\n",
       " '1270': {'13900610': 1},\n",
       " '1271': {'13768432': 1},\n",
       " '1272': {'17081238': 1},\n",
       " '1273': {'11041152': 1},\n",
       " '1274': {'12428814': 1, '27731651': 1, '4406819': 1},\n",
       " '1278': {'11335781': 1},\n",
       " '1279': {'11335781': 1},\n",
       " '1280': {'4387784': 1},\n",
       " '1281': {'4387784': 1},\n",
       " '1282': {'23649163': 1},\n",
       " '1290': {'4687948': 1},\n",
       " '1292': {'56893404': 1},\n",
       " '1298': {'11718220': 1},\n",
       " '1303': {'12631697': 1},\n",
       " '1316': {'27910499': 1},\n",
       " '1319': {'16284655': 1},\n",
       " '1320': {'16284655': 1},\n",
       " '1332': {'5304891': 1},\n",
       " '1335': {'27910499': 1},\n",
       " '1336': {'27910499': 1},\n",
       " '1337': {'20231138': 1},\n",
       " '1339': {'15482274': 1},\n",
       " '1344': {'9559146': 1},\n",
       " '1352': {'12885341': 1},\n",
       " '1359': {'11614737': 1},\n",
       " '1362': {'8290953': 1},\n",
       " '1363': {'8290953': 1},\n",
       " '1368': {'2425364': 1},\n",
       " '1370': {'2425364': 1},\n",
       " '1379': {'16322674': 1, '27123743': 1, '23557241': 1, '17450673': 1},\n",
       " '1382': {'17755060': 1},\n",
       " '1385': {'306006': 1},\n",
       " '1389': {'23895668': 1},\n",
       " '1395': {'17717391': 1}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df = pd.DataFrame({\n",
    "    'query_id': list(queries.keys()),\n",
    "    'query': list(queries.values())\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0-dimensional biomaterials show inductive prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1,000 genomes project enables mapping of genet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1/2000 in UK have abnormal PrP positivity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>5% of perinatal mortality is due to low birth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>A deficiency of vitamin B12 increases blood le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1379</td>\n",
       "      <td>Women with a higher birth weight are more like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1382</td>\n",
       "      <td>aPKCz causes tumour enhancement by affecting g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1385</td>\n",
       "      <td>cSMAC formation enhances weak ligand signalling.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1389</td>\n",
       "      <td>mTORC2 regulates intracellular cysteine levels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1395</td>\n",
       "      <td>p16INK4A accumulation is  linked to an abnorma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id                                              query\n",
       "0          1  0-dimensional biomaterials show inductive prop...\n",
       "1          3  1,000 genomes project enables mapping of genet...\n",
       "2          5         1/2000 in UK have abnormal PrP positivity.\n",
       "3         13  5% of perinatal mortality is due to low birth ...\n",
       "4         36  A deficiency of vitamin B12 increases blood le...\n",
       "..       ...                                                ...\n",
       "295     1379  Women with a higher birth weight are more like...\n",
       "296     1382  aPKCz causes tumour enhancement by affecting g...\n",
       "297     1385   cSMAC formation enhances weak ligand signalling.\n",
       "298     1389  mTORC2 regulates intracellular cysteine levels...\n",
       "299     1395  p16INK4A accumulation is  linked to an abnorma...\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:21 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries:  35%|███▍      | 104/300 [00:00<00:00, 517.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n",
      "2024-05-22 15:57:22 - Preprocessed user input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries:  69%|██████▉   | 208/300 [00:11<00:05, 16.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 15:57:33 - >>> Generated embeddings for batch 0\n",
      "2024-05-22 15:57:33 - Shape of embeddings: (128, 1024)\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries:  69%|██████▉   | 208/300 [00:11<00:05, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n",
      "2024-05-22 15:57:33 - Preprocessed user input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 300/300 [00:23<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 15:57:44 - >>> Generated embeddings for batch 1\n",
      "2024-05-22 15:57:44 - Shape of embeddings: (128, 1024)\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:44 - Preprocessed user input\n",
      "2024-05-22 15:57:45 - Preprocessed user input\n",
      "2024-05-22 15:57:45 - Preprocessed user input\n",
      "2024-05-22 15:57:45 - Preprocessed user input\n",
      "2024-05-22 15:57:48 - >>> Generated embeddings for final batch 2\n",
      "2024-05-22 15:57:48 - Shape of embeddings: (44, 1024)\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs_list = []\n",
    "retrieved_text_list = []\n",
    "query_ids = []\n",
    "batch_size = 128\n",
    "k=10\n",
    "query_batch = []\n",
    "query_embeddings_list = []\n",
    "query_ids = []\n",
    "batch_no = 0\n",
    "\n",
    "for idx, query in tqdm(queries_df.iterrows(), total=len(queries_df), desc=\"Processing queries\"):\n",
    "    query_batch.append(ingest_input(query['query'])[0])\n",
    "    \n",
    "    if len(query_batch) == batch_size:\n",
    "        query_embeddings = generate_embeddings(query_batch, device)\n",
    "        query_embeddings_list.extend(query_embeddings.tolist())\n",
    "        # query_ids.extend([query['query_id']] * batch_size)\n",
    "        \n",
    "        query_batch = []\n",
    "        logging.info(f\">>> Generated embeddings for batch {batch_no}\")\n",
    "        logging.info(f\"Shape of embeddings: {query_embeddings.shape}\")\n",
    "        batch_no += 1\n",
    "        \n",
    "# Handle any remaining queries\n",
    "if len(query_batch) > 0:\n",
    "    query_embeddings = generate_embeddings(query_batch, device)\n",
    "    query_embeddings_list.extend(query_embeddings.tolist())\n",
    "    # query_ids.extend([query['query_id']] * len(query_batch))\n",
    "    \n",
    "    logging.info(f\">>> Generated embeddings for final batch {batch_no}\")\n",
    "    logging.info(f\"Shape of embeddings: {query_embeddings.shape}\")\n",
    "\n",
    "\n",
    "# Create a DataFrame to save the results\n",
    "results_df = pd.DataFrame({\n",
    "    'query_id': query_ids,\n",
    "    f'retrieved_docs_top{k}': retrieved_docs_list,\n",
    "    f'retrieved_texts_top{k}': retrieved_text_list\n",
    "    # 'retrieved_texts': retrieved_text_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query_id           object\n",
       "query_embedding    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'query_id': queries_df['query_id'],\n",
    "    # f'retrieved_docs_top{k}': retrieved_docs_list,\n",
    "    # f'retrieved_texts_top{k}': retrieved_text_list,\n",
    "    'query_embedding': query_embeddings_list\n",
    "})\n",
    "results_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_similarity(query_embedding: np.ndarray, doc_embedding: np.ndarray):\n",
    "    # Calculate cosine similarity\n",
    "    if isinstance(doc_embedding, list):\n",
    "        doc_embedding = np.array(doc_embedding).reshape(1, -1)\n",
    "    \n",
    "    # print(f\"type of query_embedding: {type(query_embedding)}\")\n",
    "    # print(f\"type of doc_embedding: {type(doc_embedding)}\")\n",
    "    similarity = cosine_similarity(query_embedding, doc_embedding)\n",
    "    return similarity.flatten()[0]\n",
    "\n",
    "\n",
    "def find_similar_embeddings(\n",
    "    df, query_embedding, top_k=10, similarity_threshold=0.5\n",
    "):\n",
    "    # query_embedding = generate_embeddings([query_text], device=device)\n",
    "    if isinstance(query_embedding, list):\n",
    "        query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "        # query_embedding = query_embedding.flatten().reshape(1, -1)\n",
    "\n",
    "\n",
    "    # Calculate cosine similarities\n",
    "    similarities = df.apply(\n",
    "        lambda x: calculate_similarity(query_embedding, x[\"embedding\"]), axis=1\n",
    "    )\n",
    "    \n",
    "    # Create a DataFrame with similarities\n",
    "    results_df = df.copy()\n",
    "    results_df[\"similarity\"] = similarities\n",
    "\n",
    "    # Filter based on similarity thresholds\n",
    "    results_df = results_df[\n",
    "        results_df[\"similarity\"] > similarity_threshold\n",
    "    ]\n",
    "\n",
    "    # Sort and get top_k results\n",
    "    results_df = results_df.sort_values(by=\"similarity\", ascending=False).head(top_k)\n",
    "    \n",
    "    return results_df['doc_id'].values.tolist(), results_df['similarity'].values.tolist(), results_df['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding similar embeddings:  81%|████████  | 242/300 [13:29<03:17,  3.40s/it]"
     ]
    }
   ],
   "source": [
    "retrieved_docs_list = []\n",
    "retrieved_text_list = []\n",
    "retrieved_sim_list = []\n",
    "query_ids = []\n",
    "k=10\n",
    "\n",
    "for idx, row in tqdm(results_df.iterrows(), total=len(results_df), desc=\"Finding similar embeddings\"):\n",
    "    doc_ids, sim_scores, similar_texts = find_similar_embeddings(embeddings_df, row['query_embedding'], top_k=k)\n",
    "    retrieved_docs_list.append(doc_ids)\n",
    "    retrieved_sim_list.append(sim_scores)\n",
    "    retrieved_text_list.append(similar_texts)\n",
    "\n",
    "\n",
    "# Create a DataFrame to save the results\n",
    "retrieval_df = pd.DataFrame({\n",
    "    'query_id': queries_df['query_id'],\n",
    "    f'retrieved_docs_top{k}': retrieved_docs_list,\n",
    "    f'retrieved_texts_top{k}': retrieved_text_list,\n",
    "    f'retrieved_sim_top{k}': retrieved_sim_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4346436,\n",
       "  58050905,\n",
       "  15337254,\n",
       "  17388232,\n",
       "  7583104,\n",
       "  327319,\n",
       "  8290953,\n",
       "  9629682,\n",
       "  11172205,\n",
       "  19855358],\n",
       " [4414547,\n",
       "  23389795,\n",
       "  1388704,\n",
       "  19058822,\n",
       "  3662132,\n",
       "  10145528,\n",
       "  27408104,\n",
       "  13914198,\n",
       "  14717500,\n",
       "  3444507],\n",
       " [76415938,\n",
       "  9764256,\n",
       "  13734012,\n",
       "  9813098,\n",
       "  13734012,\n",
       "  9764256,\n",
       "  10300000,\n",
       "  3413083,\n",
       "  9650982,\n",
       "  9764256],\n",
       " [4791384,\n",
       "  27099731,\n",
       "  1263446,\n",
       "  33257464,\n",
       "  8529693,\n",
       "  1263446,\n",
       "  27099731,\n",
       "  49429882,\n",
       "  356218,\n",
       "  4791384],\n",
       " [3215494,\n",
       "  18557974,\n",
       "  37424881,\n",
       "  18256197,\n",
       "  10557471,\n",
       "  21636085,\n",
       "  9813098,\n",
       "  16252863,\n",
       "  11705328,\n",
       "  12130200]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
